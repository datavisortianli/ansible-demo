---
- name: Create service account for Spark
  user:
    name: "{{ spark_user }}"
    system: yes
    home: "{{ spark_lib_dir }}"
    shell: "{{ spark_user_shell }}"
    state: present
    groups: "{{ spark_user_groups | join(',') }}"

- name: Ensure Spark configuration directory exists
  file:
    path: "{{ spark_conf_dir }}"
    state: directory

- name: Ensure Spark log and run directories exist
  file:
    path: "{{ item }}"
    owner: "{{ spark_user }}"
    group: "{{ spark_user }}"
    mode: 0775
    state: directory
  with_items:
    - "{{ spark_log_dir }}"
    - "{{ spark_run_dir }}"

- name: Ensure Spark download and install directories exist
  file:
    path: "{{ item }}"
    mode: 0755
    state: directory
  with_items:
    - "{{ spark_src_dir }}"
    - "{{ spark_usr_parent_dir }}"

- name: Check if Spark dir exist
  stat:
    path: "{{ spark_usr_parent_dir }}/{{ spark_tar_name }}"
  register: spark_dir_exist

- name: Download Spark distribution
  get_url:
    url: "{{ spark_mirror }}/spark-{{ spark_version }}/{{ spark_tar_name }}.tgz"
    dest: "{{ spark_src_dir }}"
  when: not spark_dir_exist.stat.exists
  register: new_downloaded

- name: Extract Spark distribution
  unarchive:
    src: "{{ spark_src_dir }}/{{ spark_tar_name }}.tgz"
    dest: "{{ spark_usr_parent_dir }}"
    copy: false
  when: new_downloaded

- name: Setup Spark distribution symlinks
  file:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    state: link
  with_items:
    - { src: "{{ spark_usr_parent_dir }}/{{ spark_tar_name }}", dest: "{{ spark_usr_dir }}" }
    - { src: "{{ spark_usr_parent_dir }}/{{ spark_tar_name }}/conf", dest: "{{ spark_conf_dir }}/conf" }

- name: Create shims for Spark binaries
  template:
    src: spark-shim.j2
    dest: "/usr/bin/{{ item }}"
    mode: 0755
  with_items:
    - spark-class
    - spark-shell
    - spark-sql
    - spark-submit

- name: Ensure Spark work and temp work directories exist
  # Execute this task after setting up the symlinks to allow directories below them
  file:
    path: "{{ item }}"
    owner: "{{ spark_user }}"
    group: "{{ spark_user }}"
    mode: 0775
    state: directory
  with_items:
    - "{{ spark_work_dir }}"
    - "{{ spark_tmp_dir }}"

- name: Configure Spark defaults config file
  template:
    src: spark-defaults.conf.j2
    dest: "{{ spark_usr_parent_dir }}/{{ spark_tar_name }}/conf/spark-defaults.conf"

- name: Configure Spark slaves list file
  template:
    src: slaves.j2
    dest: "{{ spark_usr_parent_dir }}/{{ spark_tar_name }}/conf/slaves"
  when: Role == 'spark-master'

- name: Ensure update_slaves.sh is there
  template:
    src: update_slaves.sh.j2
    dest: /opt/datavisor/scripts/update_slaves.sh
    owner: root
    group: root
    mode: 0744
  become: true
  when: Role == 'spark-master'

- name: Set up cron job for update slaves list
  template:
    src: cron.d_update_slaves.j2
    dest: /etc/cron.d/update_slaves
    owner: root
    group: root
    mode: 0744
  become: true
  when: Role == 'spark-master'

- name: Check if systemd exists
  stat: path=/lib/systemd/system/
  register: systemd_check

- name: Create Spark Master Service (systemd)
  template:
    src: spark-master.service.j2
    dest: /etc/systemd/system/spark-master.service
    owner: root
    group: root
    mode: 0777
  become: true
  when: systemd_check.stat.exists == true and (Role == 'spark-master')
  notify: "Restart Spark Master"

- name: Configure Spark Master environment
  template:
    src: spark-env.sh.j2
    dest: "{{ spark_usr_parent_dir }}/{{ spark_tar_name }}/conf/spark-env.sh"
    mode: 0755
  notify: "Restart Spark Master"
  when: Role == 'spark-master'

- name: Configure Spark Worker environment
  template:
    src: spark-env.sh.j2
    dest: "{{ spark_usr_parent_dir }}/{{ spark_tar_name }}/conf/spark-env.sh"
    mode: 0755
  notify: "Restart Spark Worker"
  when: Role == 'spark-worker'

- name: Ensure Spark Master is running
  systemd:
    name: spark-master
    state: started
    daemon_reload: yes
  when: Role == 'spark-master'

- name: Create Spark Worker Serivce (systemd)
  template:
    src: spark-slave.service.j2
    dest: /etc/systemd/system/spark-slave.service
    owner: root
    group: root
    mode: 0777
  become: true
  when: systemd_check.stat.exists == true and (Role == 'spark-worker')
  notify: "Restart Spark Worker"

- name: Ensure Spark Worker is running
  systemd:
    name: spark-slave
    state: started
    daemon_reload: yes
  when: Role == 'spark-worker'

